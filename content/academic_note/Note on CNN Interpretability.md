---
layout: post
title: Note on CNN Interpretability
author: Binxu Wang
date: Oct 4th, 2019
comments: true
use_math: true
categories: [machine learning]
tags: [academic note, computer vision, machine learning, interpretability]
typora-copy-images-to: ../assets/img/notes/cv/
---

# Note on CNN Interpretability

2 major way of interpreting CNN

* Feature visualization: See what a hidden neuron is interested in
* Attribution: See what part of image activate a filter or detector 



## Activation Atlas 

These works try to find a tool kits for visualizing DeepNN and building up a human-computer interface of DeepNN. 

https://distill.pub/2019/activation-atlas/

https://distill.pub/2018/building-blocks/

https://distill.pub/2017/feature-visualization/

